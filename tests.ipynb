{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from lib.models.temporal_predictor import TemporalPredictor\n",
    "\n",
    "\n",
    "def load_resnet18_temporal_model(checkpoint):\n",
    "    model = TemporalPredictor(\"resnet18\",\n",
    "                              dim=512,\n",
    "                              hidden_dim=128)\n",
    "    data = torch.load(checkpoint, map_location=\"cpu\")\n",
    "\n",
    "    model.load_state_dict(data[\"model_dict\"])\n",
    "    #model = model.backbone\n",
    "    print(f\"Loaded ResNet18 model from {checkpoint}\")\n",
    "    print(f\"{sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_resnet18_temporal_model(\"models/temporal/temporal_18_beta_detach/checkpoint_90636.pth\")\n",
    "\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoon2.DigitalTyphoonDataset import DigitalTyphoonDataset as DTD\n",
    "from torchvision import transforms as T\n",
    "from lib.utils.fisheye import FishEye\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    FishEye(256, 0.2),\n",
    "])\n",
    "\n",
    "def transform_func(obj):\n",
    "    img, labels = obj\n",
    "    img_range = [150, 350]\n",
    "    img, labels = obj\n",
    "    img = (img - img_range[0])/(img_range[1]-img_range[0])\n",
    "\n",
    "    return transforms(img.astype(np.float32)), labels\n",
    "\n",
    "\n",
    "dataset = DTD(image_dir=\"/fs9/gaspar/data/WP/image/\",\n",
    "              metadata_dir=\"/fs9/gaspar/data/WP/metadata/\",\n",
    "              metadata_json=\"/fs9/gaspar/data/WP/metadata.json\",\n",
    "              get_images_by_sequence=True,\n",
    "              labels=(\"year\", \"month\", \"day\", \"hour\", \"grade\"),#(\"grade\", \"pressure\", \"wind\"),\n",
    "              split_dataset_by=\"sequence\",\n",
    "              load_data_into_memory='track',\n",
    "              filter_func= lambda x: x.grade() > 2 and x.grade() < 6,\n",
    "              transform=None,\n",
    "              ignore_list=[],\n",
    "              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "from lib.utils.fisheye import FishEye\n",
    "from lib.utils.dataset import PreprocessedTyphoonDataset\n",
    "\n",
    "transforms = T.Compose([\n",
    "    #T.ToTensor(),\n",
    "    FishEye(256,0.2),\n",
    "])\n",
    "\n",
    "def transform_func(obj):\n",
    "    img_range = [150, 350]\n",
    "    seq= obj\n",
    "    seq = (seq - img_range[0])/(img_range[1]-img_range[0])\n",
    "    seq = torch.from_numpy(seq.astype(np.float32))\n",
    "    seq = seq.unsqueeze(1)\n",
    "    return transforms(seq)#, labels\n",
    "\n",
    "\n",
    "dataset = PreprocessedTyphoonDataset(image_dir=\"/fs9/gaspar/data/WP/image/\",\n",
    "              metadata_dir=\"/fs9/gaspar/data/WP/metadata/\",\n",
    "              metadata_json=\"/fs9/gaspar/data/WP/metadata.json\",\n",
    "              labels=(\"grade\", \"pressure\", \"wind\"),\n",
    "              split_dataset_by=\"sequence\",\n",
    "              load_data_into_memory='track',\n",
    "              filter_func= lambda x: x.grade() < 6 and x.year() > 1990,\n",
    "              transform=None,\n",
    "              ignore_list=[],\n",
    "              verbose=False,\n",
    "              feature_extractor=model\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "[2000    7    4   16    5]\n",
      "[2000    7    4   18    5]\n",
      "torch.Size([1, 256, 256])\n",
      "Prediction: tensor([[0.7838]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    FishEye(256,0.2),\n",
    "])\n",
    "\n",
    "def transform_func(img):\n",
    "    img_range = [150, 350]\n",
    "    img = (img - img_range[0])/(img_range[1]-img_range[0])\n",
    "    print(img.shape)\n",
    "    return transforms(img.astype(np.float32))\n",
    "\n",
    "seq, labels = dataset[540]\n",
    "print(seq.shape)\n",
    "\n",
    "idx1 = 32\n",
    "idx2 = 34\n",
    "device = \"cuda:0\"\n",
    "img1, img2 = transform_func(seq[idx1]).to(device), transform_func(seq[idx2]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(labels[idx1])\n",
    "    print(labels[idx2])\n",
    "    print(img2.shape)\n",
    "    print(f\"Prediction: {model(img1.unsqueeze(0), img2.unsqueeze(0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[735, 157, 157] 1049\n",
      "1049\n",
      "\n",
      "735 train sequences\n",
      "157 val sequences\n",
      "157 test sequences\n"
     ]
    }
   ],
   "source": [
    "from lib.utils.dataset import SequenceTyphoonDataset as STD\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "dataset = STD(labels=[\"month\", \"day\", \"hour\", \"pressure\", \"wind\"],\n",
    "              preprocessed_path=\"resnet18_imagenet\",\n",
    "              x=[0,1,2,3,4],\n",
    "              y=[3,4],\n",
    "              num_inputs=12,\n",
    "              num_preds=1,\n",
    "              interval=3,\n",
    "              filter_func= lambda x: x.grade() < 6,\n",
    "              output_all=True)\n",
    "train, val, test = dataset.random_split([0.7, 0.15, 0.15], split_by=\"sequence\")\n",
    "\n",
    "print(f\"\\n{len(train)} train sequences\")\n",
    "print(f\"{len(val)} val sequences\")\n",
    "print(f\"{len(test)} test sequences\")\n",
    "\n",
    "test_loader = DataLoader(test,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Loading model from checkpoint /fs9/gaspar/forecoon/models/ts/larger_imagenet/checkpoint_1200.pth\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from lib.models.lstm_predictor import LSTM, AttentionLSTM\n",
    "\n",
    "def _load_checkpoint(model, path):\n",
    "    data = torch.load(path)\n",
    "    model.load_state_dict(data[\"model_dict\"])\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Loading model from checkpoint {path}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = LSTM(\n",
    "    69+512,\n",
    "    hidden_size=1024,\n",
    "    num_layers=2,\n",
    "    output_size=2\n",
    ")\n",
    "\n",
    "model = _load_checkpoint(model, \"/fs9/gaspar/forecoon/models/ts/larger_imagenet/checkpoint_1200.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=iter(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([107, 581])\n"
     ]
    }
   ],
   "source": [
    "labels = next(loader)[0]\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.dataset import NORMALIZATION\n",
    "\n",
    "pressure = lambda x: x*NORMALIZATION['pressure'][1]+NORMALIZATION['pressure'][0]\n",
    "wind = lambda x: x*NORMALIZATION['wind'][1]+NORMALIZATION['wind'][0]\n",
    "\n",
    "def evaluate_results(ys, preds, verbose=False):\n",
    "    ys = np.array([pressure(ys[0]), wind(ys[1])])\n",
    "    preds = np.array([pressure(preds[0]), wind(preds[1])])\n",
    "    diff = np.abs(preds-ys)\n",
    "    #diff_rel = diff/ys\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Pressure| true: {ys[0]:.3f} pred: {preds[0]:.3f} | diff: {diff[0]:.3f}\")# ({diff_rel[0]*100:.3f}%)\")\n",
    "        print(f\"Wind|\\t  true: {ys[1]:.3f} pred: {preds[1]:.3f} | diff: {diff[1]:.3f}\")# ({diff_rel[1]*100:.3f}%)\")\n",
    "\n",
    "    return diff#, diff_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressure| true: 1008.000 pred: 1010.517 | diff: 2.517\n",
      "Wind|\t  true: 0.000 pred: -1.577 | diff: 1.577\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def retrieve_labels(vec):\n",
    "    print(f\"Pressure: {vec[0]*NORMALIZATION['pressure'][1]+NORMALIZATION['pressure'][0]}\")\n",
    "    print(f\"Wind: {vec[1]*NORMALIZATION['wind'][1]+NORMALIZATION['wind'][0]}\")\n",
    "    #print(f\"Grade: {torch.argmax(vec[2:])}\")\n",
    "\n",
    "\n",
    "start = 6\n",
    "ins = labels[test_loader.dataset.dataset.slice_inputs(start)].unsqueeze(0)\n",
    "outs = labels[test_loader.dataset.dataset.slice_outputs(start), test_loader.dataset.dataset.y]\n",
    "with torch.no_grad():\n",
    "    evaluate_results(outs.cpu().squeeze(), model(ins).squeeze().cpu(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "errors = []\n",
    "\n",
    "for seq in tqdm(test_loader):\n",
    "    labels = seq[0]\n",
    "    for start in range(len(labels) - 13):\n",
    "        ins = labels[test_loader.dataset.dataset.slice_inputs(start), test_loader.dataset.dataset.x].unsqueeze(0)\n",
    "        outs = labels[test_loader.dataset.dataset.slice_outputs(start), test_loader.dataset.dataset.y]\n",
    "        with torch.no_grad():\n",
    "            errors.append(evaluate_results(outs.squeeze(), model(ins).squeeze()))\n",
    "\n",
    "pressure, wind = zip(*errors)\n",
    "pressure = np.mean(pressure)\n",
    "wind = np.mean(wind)\n",
    "print(pressure, wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9975586 , 1.0931053 ],\n",
       "       [1.4265137 , 0.2604561 ],\n",
       "       [1.1947021 , 3.9334984 ],\n",
       "       [1.3208008 , 0.10424423],\n",
       "       [1.5064697 , 0.34140778],\n",
       "       [1.3782959 , 3.3658638 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "@torch.no_grad()\n",
    "def forecast(model, labels, start, num_preds):\n",
    "    ws = test_loader.dataset.dataset.num_inputs\n",
    "    labs = labels[test_loader.dataset.dataset.slice_inputs(start)]\n",
    "    errors = []\n",
    "    for i in range(num_preds):\n",
    "        #print(labs.shape)\n",
    "        ins = labs[-ws:]\n",
    "        outs = labels[test_loader.dataset.dataset.slice_outputs(start+i), test_loader.dataset.dataset.y].unsqueeze(0)\n",
    "        preds = model(ins.unsqueeze(0)).squeeze()\n",
    "        # print(outs, preds)\n",
    "        errors.append(evaluate_results(outs.squeeze().cpu(), preds.cpu(), False))\n",
    "        new_data = deepcopy(labels[test_loader.dataset.dataset.slice_outputs(start+i)])\n",
    "        new_data[:,test_loader.dataset.dataset.y] = preds\n",
    "\n",
    "        labs = torch.cat((labs, new_data))\n",
    "    return np.array(errors)\n",
    "\n",
    "forecast(model, labels, 30, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [03:47<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3393258  3.156114 ]\n",
      " [ 2.2639089  4.3077245]\n",
      " [ 3.3337069  5.652008 ]\n",
      " [ 4.4285984  7.0158324]\n",
      " [ 5.5052767  8.462587 ]\n",
      " [ 6.50806    9.819918 ]\n",
      " [ 7.4444737 11.023597 ]\n",
      " [ 8.312282  12.152789 ]\n",
      " [ 9.106851  13.172267 ]\n",
      " [ 9.832729  14.046605 ]\n",
      " [10.491654  14.808446 ]\n",
      " [11.087066  15.448015 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ws = test_loader.dataset.dataset.num_inputs\n",
    "print(list(range(0, test_loader.dataset.dataset.interval*ws, test_loader.dataset.dataset.interval)))\n",
    "errors = []\n",
    "model = model.to(\"cuda\")\n",
    "for seq in tqdm(test_loader):\n",
    "    labels = seq[0].to(\"cuda\")\n",
    "    for start in range(len(labels) - (ws*2*test_loader.dataset.dataset.interval)):\n",
    "        errors.append(forecast(model, labels, start, 12))\n",
    "errors = np.array(errors)\n",
    "\n",
    "print(np.mean(errors, axis=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2280691  3.7533581]\n",
      " [ 1.8718818  4.542712 ]\n",
      " [ 2.7222672  5.52035  ]\n",
      " [ 3.661643   6.5948963]\n",
      " [ 4.5781794  7.602788 ]\n",
      " [ 5.4922676  8.527373 ]\n",
      " [ 6.4136057  9.336712 ]\n",
      " [ 7.3256984 10.119459 ]\n",
      " [ 8.204576  10.869802 ]\n",
      " [ 9.049443  11.562635 ]\n",
      " [ 9.864355  12.135972 ]\n",
      " [10.636837  12.7766075]]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(errors, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "typhoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
