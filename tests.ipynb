{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from lib.models.temporal_predictor import TemporalPredictor\n",
    "\n",
    "\n",
    "def load_resnet18_temporal_model(checkpoint):\n",
    "    model = TemporalPredictor(\"resnet18\",\n",
    "                              dim=512,\n",
    "                              hidden_dim=128)\n",
    "    data = torch.load(checkpoint, map_location=\"cpu\")\n",
    "\n",
    "    model.load_state_dict(data[\"model_dict\"])\n",
    "    #model = model.backbone\n",
    "    print(f\"Loaded ResNet18 model from {checkpoint}\")\n",
    "    print(f\"{sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_resnet18_temporal_model(\"models/temporal/temporal_18_beta_detach/checkpoint_90636.pth\")\n",
    "\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoon2.DigitalTyphoonDataset import DigitalTyphoonDataset as DTD\n",
    "from torchvision import transforms as T\n",
    "from lib.utils.fisheye import FishEye\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    FishEye(256, 0.2),\n",
    "])\n",
    "\n",
    "def transform_func(obj):\n",
    "    img, labels = obj\n",
    "    img_range = [150, 350]\n",
    "    img, labels = obj\n",
    "    img = (img - img_range[0])/(img_range[1]-img_range[0])\n",
    "\n",
    "    return transforms(img.astype(np.float32)), labels\n",
    "\n",
    "\n",
    "dataset = DTD(image_dir=\"/fs9/gaspar/data/WP/image/\",\n",
    "              metadata_dir=\"/fs9/gaspar/data/WP/metadata/\",\n",
    "              metadata_json=\"/fs9/gaspar/data/WP/metadata.json\",\n",
    "              get_images_by_sequence=True,\n",
    "              labels=(\"year\", \"month\", \"day\", \"hour\", \"grade\"),#(\"grade\", \"pressure\", \"wind\"),\n",
    "              split_dataset_by=\"sequence\",\n",
    "              load_data_into_memory='track',\n",
    "              filter_func= lambda x: x.grade() > 2 and x.grade() < 6,\n",
    "              transform=None,\n",
    "              ignore_list=[],\n",
    "              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "from lib.utils.fisheye import FishEye\n",
    "from lib.utils.dataset import PreprocessedTyphoonDataset\n",
    "\n",
    "transforms = T.Compose([\n",
    "    #T.ToTensor(),\n",
    "    FishEye(256,0.2),\n",
    "])\n",
    "\n",
    "def transform_func(obj):\n",
    "    img_range = [150, 350]\n",
    "    seq= obj\n",
    "    seq = (seq - img_range[0])/(img_range[1]-img_range[0])\n",
    "    seq = torch.from_numpy(seq.astype(np.float32))\n",
    "    seq = seq.unsqueeze(1)\n",
    "    return transforms(seq)#, labels\n",
    "\n",
    "\n",
    "dataset = PreprocessedTyphoonDataset(image_dir=\"/fs9/gaspar/data/WP/image/\",\n",
    "              metadata_dir=\"/fs9/gaspar/data/WP/metadata/\",\n",
    "              metadata_json=\"/fs9/gaspar/data/WP/metadata.json\",\n",
    "              labels=(\"grade\", \"pressure\", \"wind\"),\n",
    "              split_dataset_by=\"sequence\",\n",
    "              load_data_into_memory='track',\n",
    "              filter_func= lambda x: x.grade() < 6 and x.year() > 1990,\n",
    "              transform=None,\n",
    "              ignore_list=[],\n",
    "              verbose=False,\n",
    "              feature_extractor=model\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "[2000    7    4   16    5]\n",
      "[2000    7    4   18    5]\n",
      "torch.Size([1, 256, 256])\n",
      "Prediction: tensor([[0.7838]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    FishEye(256,0.2),\n",
    "])\n",
    "\n",
    "def transform_func(img):\n",
    "    img_range = [150, 350]\n",
    "    img = (img - img_range[0])/(img_range[1]-img_range[0])\n",
    "    print(img.shape)\n",
    "    return transforms(img.astype(np.float32))\n",
    "\n",
    "seq, labels = dataset[540]\n",
    "print(seq.shape)\n",
    "\n",
    "idx1 = 32\n",
    "idx2 = 34\n",
    "device = \"cuda:0\"\n",
    "img1, img2 = transform_func(seq[idx1]).to(device), transform_func(seq[idx2]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(labels[idx1])\n",
    "    print(labels[idx2])\n",
    "    print(img2.shape)\n",
    "    print(f\"Prediction: {model(img1.unsqueeze(0), img2.unsqueeze(0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[766, 164, 163] 1093\n",
      "1093\n",
      "\n",
      "766 train sequences\n",
      "164 val sequences\n",
      "163 test sequences\n"
     ]
    }
   ],
   "source": [
    "from lib.utils.dataset import SequenceTyphoonDataset as STD\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "dataset = STD(labels=[\"month\", \"day\", \"hour\", \"pressure\", \"wind\"],\n",
    "              include_images=False,\n",
    "              x=[0,1,2,3,4],\n",
    "              y=[3,4],\n",
    "              num_inputs=12,\n",
    "              num_preds=1,\n",
    "              filter_func= lambda x: x.grade() < 6,)\n",
    "train, val, test = dataset.random_split([0.7, 0.15, 0.15], split_by=\"sequence\")\n",
    "\n",
    "print(f\"\\n{len(train)} train sequences\")\n",
    "print(f\"{len(val)} val sequences\")\n",
    "print(f\"{len(test)} test sequences\")\n",
    "\n",
    "test_loader = DataLoader(test,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Loading model from checkpoint /fs9/gaspar/forecoon/models/ts/biglstm/checkpoint_1200.pth\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from lib.models.lstm_predictor import LSTM\n",
    "\n",
    "def _load_checkpoint(model, path):\n",
    "    data = torch.load(path)\n",
    "    model.load_state_dict(data[\"model_dict\"])\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Loading model from checkpoint {path}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = LSTM(\n",
    "    69,\n",
    "    hidden_size=512,\n",
    "    num_layers=2,\n",
    "    output_size=2\n",
    ")\n",
    "\n",
    "model = _load_checkpoint(model, \"/fs9/gaspar/forecoon/models/ts/biglstm/checkpoint_1200.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=iter(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([271, 69])\n"
     ]
    }
   ],
   "source": [
    "labels = next(loader)[0]\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.dataset import NORMALIZATION\n",
    "\n",
    "pressure = lambda x: x*NORMALIZATION['pressure'][1]+NORMALIZATION['pressure'][0]\n",
    "wind = lambda x: x*NORMALIZATION['wind'][1]+NORMALIZATION['wind'][0]\n",
    "\n",
    "def evaluate_results(ys, preds, verbose=False):\n",
    "    ys = np.array([pressure(ys[0]), wind(ys[1])])\n",
    "    preds = np.array([pressure(preds[0]), wind(preds[1])])\n",
    "    diff = np.abs(preds-ys)\n",
    "    #diff_rel = diff/ys\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Pressure| true: {ys[0]:.3f} pred: {preds[0]:.3f} | diff: {diff[0]:.3f}\")# ({diff_rel[0]*100:.3f}%)\")\n",
    "        print(f\"Wind|\\t  true: {ys[1]:.3f} pred: {preds[1]:.3f} | diff: {diff[1]:.3f}\")# ({diff_rel[1]*100:.3f}%)\")\n",
    "\n",
    "    return diff#, diff_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8356,  1.0183],\n",
      "        [-0.9111,  1.0183],\n",
      "        [-0.9822,  1.0183],\n",
      "        [-1.0578,  1.0183],\n",
      "        [-1.1333,  1.0183],\n",
      "        [-1.2044,  1.0183],\n",
      "        [-1.2800,  1.1713],\n",
      "        [-1.3156,  1.1713],\n",
      "        [-1.3556,  1.1713],\n",
      "        [-1.3911,  1.1713],\n",
      "        [-1.4267,  1.1713],\n",
      "        [-1.4667,  1.1713],\n",
      "        [-1.5022,  1.3242]], device='cuda:0')\n",
      "Pressure| true: 950.000 pred: 949.449 | diff: 0.551\n",
      "Wind|\t  true: 80.000 pred: 77.272 | diff: 2.728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def retrieve_labels(vec):\n",
    "    print(f\"Pressure: {vec[0]*NORMALIZATION['pressure'][1]+NORMALIZATION['pressure'][0]}\")\n",
    "    print(f\"Wind: {vec[1]*NORMALIZATION['wind'][1]+NORMALIZATION['wind'][0]}\")\n",
    "    #print(f\"Grade: {torch.argmax(vec[2:])}\")\n",
    "\n",
    "\n",
    "start = 60\n",
    "ins = labels[start:start+12, test_loader.dataset.dataset.x].unsqueeze(0)\n",
    "print(labels[start:start+13,test_loader.dataset.dataset.y])\n",
    "outs = labels[start+12, test_loader.dataset.dataset.y]\n",
    "with torch.no_grad():\n",
    "    evaluate_results(outs.cpu(), model(ins).squeeze().cpu(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "errors = []\n",
    "\n",
    "for seq in tqdm(test_loader):\n",
    "    labels = seq[0]\n",
    "    for start in range(len(labels) - 13):\n",
    "        ins = labels[start:start+12, test_loader.dataset.dataset.x].unsqueeze(0)\n",
    "        outs = labels[start+12, test_loader.dataset.dataset.y]\n",
    "        with torch.no_grad():\n",
    "            errors.append(evaluate_results(outs, model(ins).squeeze()))\n",
    "\n",
    "pressure, wind = zip(*errors)\n",
    "pressure = np.mean(pressure)\n",
    "wind = np.mean(wind)\n",
    "print(pressure, wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "@torch.no_grad()\n",
    "def forecast(model, labels, start, num_preds, ws = 12):\n",
    "    labs = labels[start:start+ws, test_loader.dataset.dataset.x]\n",
    "    errors = []\n",
    "    for i in range(num_preds):\n",
    "        #print(labs.shape)\n",
    "        ins = labs[-ws:]\n",
    "        outs = labels[start+i+ws, test_loader.dataset.dataset.y].unsqueeze(0)\n",
    "        preds = model(ins.unsqueeze(0)).squeeze()\n",
    "        # print(outs, preds)\n",
    "        errors.append(evaluate_results(outs.squeeze().cpu(), preds.cpu(), False))\n",
    "        new_data = deepcopy(labels[start+i+ws, test_loader.dataset.dataset.x])\n",
    "        new_data[test_loader.dataset.dataset.y] = preds\n",
    "\n",
    "        labs = torch.cat((labs, new_data.unsqueeze(0)))\n",
    "    return np.array(errors)\n",
    "\n",
    "forecast(model, labels, 30, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [04:29<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42775998 1.6701598 ]\n",
      " [0.7797613  2.5322058 ]\n",
      " [1.1943138  3.2235363 ]\n",
      " [1.6340176  3.8211486 ]\n",
      " [2.080834   4.4243484 ]\n",
      " [2.535665   5.026475  ]\n",
      " [2.9965143  5.677689  ]\n",
      " [3.452464   6.3041677 ]\n",
      " [3.9112203  6.9336143 ]\n",
      " [4.3745546  7.5578766 ]\n",
      " [4.840257   8.169381  ]\n",
      " [5.310988   8.750622  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ws = 12\n",
    "errors = []\n",
    "model = model.to(\"cuda\")\n",
    "for seq in tqdm(test_loader):\n",
    "    labels = seq[0].to(\"cuda\")\n",
    "    for start in range(len(labels) - (ws*2)):\n",
    "        errors.append(forecast(model, labels, start, ws, ws))\n",
    "errors = np.array(errors)\n",
    "\n",
    "print(np.mean(errors, axis=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59710056 3.186433  ]\n",
      " [1.0784663  4.0809026 ]\n",
      " [1.5833673  4.7050915 ]\n",
      " [2.0881422  5.2325544 ]\n",
      " [2.5937524  5.712854  ]\n",
      " [3.1028488  6.160838  ]\n",
      " [3.5992775  6.5368648 ]\n",
      " [4.095794   6.8820863 ]\n",
      " [4.5897317  7.2306066 ]\n",
      " [5.073547   7.5753455 ]\n",
      " [5.547339   7.9324613 ]\n",
      " [6.0154667  8.2943945 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(errors, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "typhoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
